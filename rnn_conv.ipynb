{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "from scipy.signal import spectrogram, istft\n",
    "from librispeech_mixer import LibriSpeechMixer\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling2D, Conv2DTranspose, UpSampling2D, Reshape, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.contrib.layers import flatten\n",
    "import IPython\n",
    "from os import listdir\n",
    "from keras import backend as K\n",
    "from separation import bss_eval_sources\n",
    "\n",
    "def mask_to_outputs(mixed_real, mixed_imag, scaled_mask_real, scaled_mask_imag, C, K):\n",
    "    unscaled_mask_real = -tf.log((K - scaled_mask_real)/(K + scaled_mask_real+1e-10)+1e-30)/C\n",
    "    unscaled_mask_imag = -tf.log((K - scaled_mask_imag)/(K + scaled_mask_imag+1e-10)+1e-30)/C\n",
    "\n",
    "    sep1 = tf.multiply(tf.complex(unscaled_mask_real, unscaled_mask_imag), tf.complex(mixed_real, mixed_imag))\n",
    "    sep2 = tf.complex(mixed_real, mixed_imag) - sep1\n",
    "\n",
    "    return sep1, sep2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "K.set_learning_phase(1) #set learning phase\n",
    "\n",
    "#Create the LibriSpeech mixer\n",
    "mixer = LibriSpeechMixer(dataset_built=True)\n",
    "\n",
    "#parse function to get data from the dataset correctly\n",
    "def _parse_function(example_proto):\n",
    "    keys_to_features = {'mixed_real':tf.FixedLenFeature((mixer.spec_length, mixer.nb_freq), tf.float32),\n",
    "                        'mixed_imag':tf.FixedLenFeature((mixer.spec_length, mixer.nb_freq), tf.float32),\n",
    "                        'mask_real': tf.FixedLenFeature((mixer.spec_length, mixer.nb_freq), tf.float32),\n",
    "                        'mask_imag': tf.FixedLenFeature((mixer.spec_length, mixer.nb_freq), tf.float32),\n",
    "                        }\n",
    "    parsed_features = tf.parse_single_example(example_proto, keys_to_features)\n",
    "    return tf.concat([parsed_features['mixed_real'], parsed_features['mixed_imag']], axis=1),\\\n",
    "            tf.concat([parsed_features['mask_real'], parsed_features['mask_imag']], axis=1)\n",
    "\n",
    "#Create the dataset object\n",
    "batch_size = 64\n",
    "\n",
    "#Placeholder to be able to specify either the training or validation set\n",
    "filenames = tf.placeholder(tf.string, shape=[None])\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(_parse_function)\n",
    "dataset = dataset.shuffle(buffer_size=2500)\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.repeat()\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "x_pl, y_pl = iterator.get_next()\n",
    "\n",
    "training_filenames = [\"/mnt/train/\" + filename for filename in [listdir(\"/mnt/train/\")]]\n",
    "validation_filenames = [\"/mnt/dev/\" + filename for filename in listdir(\"/mnt/dev/\")]\n",
    "\n",
    "\n",
    "height, width, nchannels = mixer.nb_freq, mixer.spec_length, 1\n",
    "padding = 'same'\n",
    "\n",
    "filters = mixer.nb_freq*2\n",
    "kernel_size = 3\n",
    "kernel_size_2 = (2,20)\n",
    "pool_size_1 = (2,4)\n",
    "pool_size_2 = (4,4)\n",
    "\n",
    "print('Trace of the tensors shape as it is propagated through the network.')\n",
    "print('Layer name \\t Output size')\n",
    "print('----------------------------')\n",
    "\n",
    "with tf.variable_scope('convLayer1'):\n",
    "    #batch_norm = BatchNormalization(axis=2)\n",
    "\n",
    "    #x = batch_norm(x_pl)\n",
    "    #dropout = Dropout(0.2)\n",
    "    #x = dropout(x_pl)\n",
    "    conv1 = Conv1D(round(5*filters/6), kernel_size, padding=padding, activation='relu')\n",
    "    print('x_pl \\t\\t', x_pl.get_shape())\n",
    "    x = conv1(x_pl)\n",
    "    print('conv1 \\t\\t', x.get_shape())\n",
    "\n",
    "    #batch_norm = BatchNormalization(axis=2)\n",
    "\n",
    "    #x = batch_norm(x)\n",
    "    #dropout = Dropout(0.2)\n",
    "    #x = dropout(x)\n",
    "    conv2 = Conv1D(round(4*filters/6), kernel_size, padding=padding, activation='relu')\n",
    "    x = conv2(x)\n",
    "    print('conv2 \\t\\t', x.get_shape())\n",
    "\n",
    "    #dropout = Dropout(0.2)\n",
    "    #x = dropout(x)\n",
    "    conv3 = Conv1D(round(filters/2), kernel_size, padding=padding, activation='relu')\n",
    "    x = conv3(x)\n",
    "    print('conv3 \\t\\t', x.get_shape())\n",
    "\n",
    "    enc_cell = tf.nn.rnn_cell.GRUCell(mixer.nb_freq*2, activation = tf.tanh)\n",
    "    y, enc_state = tf.nn.dynamic_rnn(cell=enc_cell, inputs=x,\n",
    "                                     dtype=tf.float32)\n",
    "    y = y * mixer.K\n",
    "print('Model consits of ', utils.num_params(), 'trainable parameters.')\n",
    "\n",
    "# restricting memory usage, TensorFlow is greedy and will use all memory otherwise\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.99)\n",
    "\"\"\"## Launch TensorBoard, and visualize the TF graph\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "    tmp_def = utils.rename_nodes(sess.graph_def, lambda s:\"/\".join(s.split('_',1)))\n",
    "    utils.show_graph(tmp_def)\"\"\"\n",
    "\n",
    "\n",
    "with tf.variable_scope('loss'):\n",
    "    # The loss takes the amplitude of the output into account, in order to avoid taking care of noise\n",
    "    y_target1, y_target2 = mask_to_outputs(x_pl[:, :, :mixer.nb_freq], x_pl[:, :, mixer.nb_freq:],\\\n",
    "                                            y_pl[:, :, :mixer.nb_freq], y_pl[:, :, mixer.nb_freq:], mixer.C, mixer.K)\n",
    "\n",
    "    y_pred1, y_pred2 = mask_to_outputs(x_pl[:, :, :mixer.nb_freq], x_pl[:, :, mixer.nb_freq:],\\\n",
    "                                            y[:, :, :mixer.nb_freq], y[:, :, mixer.nb_freq:], mixer.C, mixer.K)\n",
    "    \n",
    "    mean_square_error = tf.reduce_mean((tf.real(y_target1) - tf.real(y_pred1))**2 + \\\n",
    "                                        (tf.real(y_target2) - tf.real(y_pred2))**2 + \\\n",
    "                                        (tf.imag(y_target1) - tf.imag(y_pred1))**2 + \\\n",
    "                                        (tf.imag(y_target2) - tf.imag(y_pred2))**2)\n",
    "    eval_indexes = bss_eval_sources( np.array([y_target1, y_target2]), np.array([y_pred1, y_pred2]) )\n",
    "\n",
    "    #L2 regularization\n",
    "    \"\"\"reg_scale = 0.01\n",
    "    regularize = tf.contrib.layers.l2_regularizer(reg_scale)\n",
    "    params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    reg_term = sum([regularize(param) for param in params])\n",
    "    mean_square_error += reg_term\"\"\"\n",
    "\n",
    "with tf.variable_scope('training'):\n",
    "    # defining our optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "\n",
    "    # applying the gradients\n",
    "    train_op = optimizer.minimize(mean_square_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Training\n",
    "\n",
    "#Training Loop\n",
    "\n",
    "max_epochs = 25\n",
    "\n",
    "\n",
    "valid_loss = []\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "\n",
    "def trainingLoop():\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(iterator.initializer, feed_dict={filenames: training_filenames})\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('Begin training loop')\n",
    "        \n",
    "        nb_batches_processed = 0\n",
    "        nb_epochs = 0\n",
    "        try:\n",
    "\n",
    "            while nb_epochs < max_epochs:\n",
    "                _train_loss = []\n",
    "\n",
    "                ## Run train op\n",
    "                fetches_train = [train_op, mean_square_error]\n",
    "                _, _loss = sess.run(fetches_train)\n",
    "\n",
    "                _train_loss.append(_loss)\n",
    "                \n",
    "                nb_batches_processed += 1\n",
    "                \n",
    "                ## Compute validation loss once per epoch\n",
    "                if round(nb_batches_processed/mixer.nb_seg_train*batch_size-0.5) > nb_epochs:\n",
    "                    nb_epochs += 1\n",
    "                    \n",
    "                    sess.run(iterator.initializer, feed_dict={filenames: validation_filenames})\n",
    "                    _valid_loss = []\n",
    "                    train_loss.append(np.mean(_train_loss))\n",
    "\n",
    "                    fetches_valid = [mean_square_error]\n",
    "                    \n",
    "                    nb_test_batches_processed = 0\n",
    "                    #Proceed to a whole testing epoch\n",
    "                    while round(nb_test_batches_processed/mixer.nb_seg_test*batch_size-0.5) < 1:\n",
    "                        \n",
    "                        _loss = sess.run(fetches_valid)\n",
    "\n",
    "                        _valid_loss.append(_loss)\n",
    "                        nb_test_batches_processed += 1\n",
    "                        \n",
    "                    valid_loss.append(np.mean(_valid_loss))\n",
    "\n",
    "\n",
    "                    print(\"Epoch {} : Train Loss {:6.3f}, Valid loss {:6.3f}\".format(\n",
    "                        nb_epochs, train_loss[-1], valid_loss[-1]))\n",
    "                    sess.run(iterator.initializer, feed_dict={filenames: training_filenames})\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "        \n",
    "        save_path = saver.save(sess, \"./model.ckpt\")\n",
    "            \n",
    "        #Display how the model perform, mask and sound\n",
    "        x_batch, y_batch, phase = sess.run(iterator.get_next())\n",
    "        phase = np.transpose(phase[0,:,:])\n",
    "        x_batch = np.transpose(x_batch)\n",
    "        y_batch = np.transpose(y_batch)\n",
    "        y_pred = np.transpose(sess.run(fetches=y))\n",
    "        \n",
    "        sp_y1_targ = np.multiply(x_batch[0,:,:],y_batch[0,:,:])\n",
    "        sp_y1_rec = np.multiply(x_batch[0,:,:],y_pred[0,:,:])\n",
    "        sp_y2_targ = np.multiply((np.ones(x_batch[0,:,:].shape)-y_batch[0,:,:]), x_batch[0,:,:])\n",
    "        sp_y2_rec = np.multiply((np.ones(x_batch[0,:,:].shape)-y_pred[0,:,:]), x_batch[0,:,:])\n",
    "\n",
    "        sp_y1_rec_phase = []\n",
    "        for i in range(len(sp_y1_rec)):\n",
    "            rec_line = []\n",
    "            for n in range(len(sp_y1_rec[0])) :\n",
    "                rec_line.append( sp_y1_rec[i][n]*np.cos(phase[i][n]) + 1j*sp_y1_rec[i][n]*np.sin(phase[i][n]) )\n",
    "\n",
    "            sp_y1_rec_phase.append(rec_line)\n",
    "            \n",
    "        sp_y2_rec_phase = []\n",
    "        for i in range(len(sp_y2_rec)):\n",
    "            rec_line = []\n",
    "            for n in range(len(sp_y2_rec[0])) :\n",
    "                rec_line.append( sp_y2_rec[i][n]*np.cos(phase[i][n]) + 1j*sp_y2_rec[i][n]*np.sin(phase[i][n]) )\n",
    "\n",
    "            sp_y2_rec_phase.append(rec_line)\n",
    "            \n",
    "        sp_y1_targ_phase = []\n",
    "        for i in range(len(sp_y1_targ)):\n",
    "            rec_line = []\n",
    "            for n in range(len(sp_y1_targ[0])) :\n",
    "                rec_line.append( sp_y1_targ[i][n]*np.cos(phase[i][n]) + 1j*sp_y1_targ[i][n]*np.sin(phase[i][n]) )\n",
    "\n",
    "            sp_y1_targ_phase.append(rec_line)\n",
    "            \n",
    "        sp_y2_targ_phase = []\n",
    "        for i in range(len(sp_y2_targ)):\n",
    "            rec_line = []\n",
    "            for n in range(len(sp_y2_targ[0])) :\n",
    "                rec_line.append(sp_y2_targ[i][n]*np.cos(phase[i][n]) + 1j*sp_y2_targ[i][n]*np.sin(phase[i][n]) )\n",
    "\n",
    "            sp_y2_targ_phase.append(rec_line)\n",
    "        \n",
    "        framerate=16000\n",
    "        print(sp_y1_targ_phase)\n",
    "        t1, y1_targ = istft(sp_y1_targ_phase, fs=framerate)\n",
    "        print('Speaker A target')\n",
    "        IPython.display.display(IPython.display.Audio(y1_targ,rate=framerate))\n",
    "        \n",
    "        t1, y1_rec = istft(sp_y1_rec_phase, fs=framerate)\n",
    "        print('Speaker A prediction')\n",
    "        IPython.display.display(IPython.display.Audio(y1_rec,rate=framerate))\n",
    "        \n",
    "        t2, y2_targ = istft(sp_y2_targ_phase, fs=framerate)\n",
    "        print('Speaker B target')\n",
    "        IPython.display.display(IPython.display.Audio(y2_targ,rate=framerate))\n",
    "        \n",
    "        t2, y2_rec = istft(sp_y2_rec_phase, fs=framerate)\n",
    "        print('Speaker B prediction')\n",
    "        IPython.display.display(IPython.display.Audio(y2_rec,rate=framerate))\n",
    "\n",
    "        \n",
    "        plt.pcolormesh(10 * np.log10(x_batch[0,:,:]+1e-10))\n",
    "        plt.axis('tight')\n",
    "        plt.ylabel('Frequency [Hz]')\n",
    "        plt.xlabel('Time [sec]')\n",
    "        plt.title('Input')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        \n",
    "                       \n",
    "        plt.pcolormesh(y_batch[0,:,:])\n",
    "        plt.axis('tight')\n",
    "        plt.ylabel('Frequency [Hz]')\n",
    "        plt.xlabel('Time [sec]')\n",
    "        plt.title('Real mask')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.pcolormesh(y_pred[0,:,:])\n",
    "        plt.axis('tight')\n",
    "        plt.ylabel('Frequency [Hz]')\n",
    "        plt.xlabel('Time [sec]')\n",
    "        plt.title('Predicted mask')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "trainingLoop();\n",
    "\n",
    "\n",
    "    \n",
    "epoch = np.arange(len(train_loss))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_loss,'r', epoch, valid_loss,'b')\n",
    "plt.legend(['Train Loss','Val Loss'], loc=4)\n",
    "plt.xlabel('Epochs'), plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask_to_outputs_np(mixed_real, mixed_imag, scaled_mask_real, scaled_mask_imag, C, K):\n",
    "    unscaled_mask_real = -np.log((K - scaled_mask_real)/(K + scaled_mask_real+1e-10)+1e-30)/C\n",
    "    unscaled_mask_imag = -np.log((K - scaled_mask_imag)/(K + scaled_mask_imag+1e-10)+1e-30)/C\n",
    "\n",
    "    sep1 = np.multiply(unscaled_mask_real +  1j * unscaled_mask_imag, mixed_real + 1j * mixed_imag)\n",
    "    sep2 = mixed_real + 1j * mixed_imag - sep1\n",
    "\n",
    "    return sep1, sep2\n",
    "\n",
    "#Load the saved model and test it\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer, feed_dict={filenames: training_filenames})\n",
    "    saver.restore(sess, \"model.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    x_batch, y_batch = sess.run(iterator.get_next())\n",
    "\n",
    "    print(y_batch)\n",
    "\n",
    "    y_batch = np.transpose(y_batch, axes=[0,2,1])\n",
    "    \n",
    "    y_pred = np.transpose(sess.run(fetches=y, feed_dict={x_pl: x_batch}), axes = [0,2,1])\n",
    "    \n",
    "    print(y_pred)\n",
    "    x_batch = np.transpose(x_batch, axes=[0,2,1])\n",
    "    sp_y1_targ, sp_y2_targ = mask_to_outputs_np(x_batch[0, :mixer.nb_freq, :], x_batch[0, mixer.nb_freq:, :],\\\n",
    "                                            y_batch[0, :mixer.nb_freq, :], y_batch[0, mixer.nb_freq:, :], mixer.C, mixer.K)\n",
    "\n",
    "    sp_y1_rec, sp_y2_rec = mask_to_outputs_np(x_batch[0, :mixer.nb_freq, :], x_batch[0, mixer.nb_freq:, :],\\\n",
    "                                            y_pred[0, :mixer.nb_freq, :], y_pred[0, mixer.nb_freq:, :], mixer.C, mixer.K) \n",
    "\n",
    "    framerate=16000\n",
    "\n",
    "    t1, y1_targ = istft(sp_y1_targ, fs=framerate)\n",
    "    print('Speaker A target')\n",
    "    IPython.display.display(IPython.display.Audio(y1_targ,rate=framerate))\n",
    "    \n",
    "    t1, y1_rec = istft(sp_y1_rec, fs=framerate)\n",
    "    print('Speaker A prediction')\n",
    "    IPython.display.display(IPython.display.Audio(y1_rec,rate=framerate))\n",
    "\n",
    "    t2, y2_targ = istft(sp_y2_targ, fs=framerate)\n",
    "    print('Speaker B target')\n",
    "    IPython.display.display(IPython.display.Audio(y2_targ,rate=framerate))\n",
    "\n",
    "    t2, y2_rec = istft(sp_y2_rec, fs=framerate)\n",
    "    print('Speaker B prediction')\n",
    "    IPython.display.display(IPython.display.Audio(y2_rec,rate=framerate))\n",
    "        \n",
    "    #indexes = bss_eval_sources([y1_targ, y2_tagr],[y1_rec, y2_rec])\n",
    "    \n",
    "    \n",
    "    wavfile.write('spkA_target.wav', framerate, y1_targ)\n",
    "    wavfile.write('spkA_prediction.wav', framerate, y1_rec)\n",
    "    wavfile.write('spkB_target.wav', framerate, y2_targ)\n",
    "    wavfile.write('spkB_prediction.wav', framerate, y2_rec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_epoch = 1\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "    saver = tf.train.Saver()    \n",
    "    sess.run(iterator.initializer, feed_dict={filenames: training_filenames})\n",
    "    saver.restore(sess, \"model.ckpt\")\n",
    "\n",
    "    nb_batches_processed = 0\n",
    "    nb_epochs = 0\n",
    "    try:\n",
    "\n",
    "        while nb_epochs < max_epochs:\n",
    "            _train_indexes = []\n",
    "\n",
    "            ## Run train op\n",
    "            fetches_train = [eval_indexes]\n",
    "\n",
    "            _indexes = sess.run(fetches_train)\n",
    "            _train_indexes.append([_indexes[0], _indexes[1], _indexes[2]])\n",
    "\n",
    "            nb_batches_processed += 1\n",
    "\n",
    "            ## Compute validation loss once per epoch\n",
    "            if round(nb_batches_processed/mixer.nb_seg_train*batch_size-0.5) > nb_epochs:\n",
    "                nb_epochs += 1\n",
    "\n",
    "                sess.run(iterator.initializer, feed_dict={filenames: validation_filenames})\n",
    "                _valid_indexes = []\n",
    "                train_indexes.append(np.mean(np.array(_train_indexes), axis = 0))\n",
    "\n",
    "                fetches_valid = [eval_indexes]\n",
    "\n",
    "                nb_test_batches_processed = 0\n",
    "                #Proceed to a whole testing epoch\n",
    "                while round(nb_test_batches_processed/mixer.nb_seg_test*batch_size-0.5) < 1:\n",
    "\n",
    "                    _indexes = sess.run(fetches_valid)\n",
    "\n",
    "                    _valid_indexes.append([_indexes[0], _indexes[1], _indexes[2]])\n",
    "                    nb_test_batches_processed += 1\n",
    "\n",
    "                valid_indexes.append(np.mean(np.array(_valid_indexes), axis = 0))\n",
    "\n",
    "\n",
    "                print(\"train indexes:\", train_indexes[-1], \n",
    "                      \"valid indexes\", valid_indexes[-1])\n",
    "                sess.run(iterator.initializer, feed_dict={filenames: training_filenames})\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
