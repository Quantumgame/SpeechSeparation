{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "from scipy.signal import spectrogram, istft\n",
    "from test_mixer import TestMixer\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Conv2DTranspose, UpSampling2D, Reshape, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.contrib.layers import flatten\n",
    "import IPython\n",
    "from os import listdir\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "K.set_learning_phase(1) #set learning phase\n",
    "\n",
    "#Create the LibriSpeech mixer\n",
    "mixer = TestMixer(nbSpeakers=10, nbSamples=200, dataset_built=True)\n",
    "\n",
    "#parse function to get data from the dataset correctly\n",
    "def _parse_function(example_proto):\n",
    "    keys_to_features = {'mixed_abs':tf.FixedLenFeature((mixer.nb_freq, mixer.spec_length, 1), tf.float32),\n",
    "                        'mask': tf.FixedLenFeature((mixer.nb_freq, mixer.spec_length, 1), tf.float32),\n",
    "                        'mixed_phase':tf.FixedLenFeature((mixer.nb_freq, mixer.spec_length, 1), tf.float32)\n",
    "                        }\n",
    "    parsed_features = tf.parse_single_example(example_proto, keys_to_features)\n",
    "    return parsed_features['mixed_abs'], parsed_features['mask'], parsed_features['mixed_phase']\n",
    "\n",
    "#Create the dataset object\n",
    "batch_size = 64\n",
    "\n",
    "#Placeholder to be able to specify either the training or validation set\n",
    "filenames = tf.placeholder(tf.string, shape=[None])\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(_parse_function)\n",
    "dataset = dataset.shuffle(buffer_size=10000)\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.repeat()\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "x_pl, y_pl,_ = iterator.get_next()\n",
    "\n",
    "training_filenames = [\"Data/train/\" + filename for filename in listdir(\"Data/train/\")]\n",
    "validation_filenames = [\"Data/dev/\" + filename for filename in listdir(\"Data/dev/\")]\n",
    "\n",
    "\n",
    "height, width, nchannels = mixer.nb_freq, mixer.spec_length, 1\n",
    "padding = 'same'\n",
    "\n",
    "filters_1 = 4\n",
    "kernel_size_1 = (20,2)\n",
    "kernel_size_2 = (2,20)\n",
    "pool_size_1 = (2,4)\n",
    "pool_size_2 = (4,4)\n",
    "\n",
    "print('Trace of the tensors shape as it is propagated through the network.')\n",
    "print('Layer name \\t Output size')\n",
    "print('----------------------------')\n",
    "\n",
    "#the channeldimension is unuseful here, and time needs to be before frequancies\n",
    "print(x_pl.shape)\n",
    "x_pl = tf.transpose(tf.reshape(x_pl, [-1,mixer.nb_freq, mixer.spec_length]), perm=[0,2,1])\n",
    "y_pl = tf.transpose(tf.reshape(y_pl, [-1,mixer.nb_freq, mixer.spec_length]), perm=[0,2,1])\n",
    "#t_mask = tf.placeholder(tf.float32, shape=[None, None], name='t_mask')\n",
    "#X_len = tf.placeholder(tf.int32, shape=[None], name='X_len')\n",
    "print(x_pl.shape)\n",
    "enc_cell = tf.nn.rnn_cell.GRUCell(128, activation = tf.sigmoid)\n",
    "y, enc_state = tf.nn.dynamic_rnn(cell=enc_cell, inputs=x_pl,\n",
    "                                 dtype=tf.float32)\n",
    "print(y.shape)\n",
    "\n",
    "print('Model consits of ', utils.num_params(), 'trainable parameters.')\n",
    "\n",
    "# restricting memory usage, TensorFlow is greedy and will use all memory otherwise\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=1.0)\n",
    "\"\"\"## Launch TensorBoard, and visualize the TF graph\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "    tmp_def = utils.rename_nodes(sess.graph_def, lambda s:\"/\".join(s.split('_',1)))\n",
    "    utils.show_graph(tmp_def)\"\"\"\n",
    "\n",
    "\n",
    "with tf.variable_scope('loss'):\n",
    "    # The loss takes the amplitude of the output into account, in order to avoid taking care of noise\n",
    "    y_target1 = 10*tf.log(tf.multiply(x_pl, y_pl)+1e-10)/np.log(10)\n",
    "    y_target2 = 10*tf.log(tf.multiply(x_pl, (1-y_pl))+1e-10)/np.log(10)\n",
    "    y_pred1 = 10*tf.log(tf.multiply(x_pl, y)+1e-10)/np.log(10)\n",
    "    y_pred2 = 10*tf.log(tf.multiply(x_pl, (1-y))+1e-10)/np.log(10)\n",
    "    mean_square_error = tf.reduce_mean((y_target1 - y_pred1)**2) + tf.reduce_mean((y_target2 - y_pred2)**2)\n",
    "    #mean_square_error = tf.reduce_mean(tf.multiply(t_mask,(y_target1 - y_pred1)**2)) + tf.reduce_mean(tf.multiply(t_mask,(y_target2 - y_pred2)**2))\n",
    "\n",
    "\n",
    "\n",
    "with tf.variable_scope('training'):\n",
    "    # defining our optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "    # applying the gradients\n",
    "    train_op = optimizer.minimize(mean_square_error)\n",
    "\n",
    "#Test the forward pass\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "    sess.run(iterator.initializer, feed_dict={filenames: training_filenames})\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    y_pred = sess.run(fetches=y)\n",
    "\n",
    "assert y_pred.shape[1:] == y_pl.shape[1:], \"ERROR the output shape is not as expected!\"         + \" Output shape should be \" + str(y_pl.shape) + ' but was ' + str(y_pred.shape)\n",
    "\n",
    "print('Forward pass successful!')\n",
    "\n",
    "\n",
    "# ## Training\n",
    "\n",
    "#Training Loop\n",
    "\n",
    "max_epochs = 25\n",
    "\n",
    "\n",
    "valid_loss = []\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "\n",
    "def trainingLoop():\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(iterator.initializer, feed_dict={filenames: training_filenames})\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('Begin training loop')\n",
    "        \n",
    "        nb_batches_processed = 0\n",
    "        nb_epochs = 0\n",
    "        try:\n",
    "\n",
    "            while nb_epochs < max_epochs:\n",
    "                _train_loss = []\n",
    "\n",
    "                ## Run train op\n",
    "                fetches_train = [train_op, mean_square_error]\n",
    "                _, _loss = sess.run(fetches_train)\n",
    "\n",
    "                _train_loss.append(_loss)\n",
    "                \n",
    "                nb_batches_processed += 1\n",
    "                \n",
    "                ## Compute validation loss once per epoch\n",
    "                if round(nb_batches_processed/mixer.nb_seg_train*batch_size-0.5) > nb_epochs:\n",
    "                    nb_epochs += 1\n",
    "                    \n",
    "                    sess.run(iterator.initializer, feed_dict={filenames: validation_filenames})\n",
    "                    _valid_loss = []\n",
    "                    train_loss.append(np.mean(_train_loss))\n",
    "\n",
    "                    fetches_valid = [mean_square_error]\n",
    "                    \n",
    "                    nb_test_batches_processed = 0\n",
    "                    #Proceed to a whole testing epoch\n",
    "                    while round(nb_test_batches_processed/mixer.nb_seg_test*batch_size-0.5) < 1:\n",
    "                        \n",
    "                        _loss = sess.run(fetches_valid)\n",
    "\n",
    "                        _valid_loss.append(_loss)\n",
    "                        nb_test_batches_processed += 1\n",
    "                        \n",
    "                    valid_loss.append(np.mean(_valid_loss))\n",
    "\n",
    "\n",
    "                    print(\"Epoch {} : Train Loss {:6.3f}, Valid loss {:6.3f}\".format(\n",
    "                        nb_epochs, train_loss[-1], valid_loss[-1]))\n",
    "                    sess.run(iterator.initializer, feed_dict={filenames: training_filenames})\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "        \n",
    "        #Display how the model perform, mask and sound\n",
    "        x_batch, y_batch, phase = sess.run(iterator.get_next())\n",
    "        phase = phase[0,:,:]\n",
    "        y_pred = sess.run(fetches=y)\n",
    "        \n",
    "        sp_y1_targ = np.multiply(x_batch[0,:,:],y_batch[0,:,:])\n",
    "        sp_y1_rec = np.multiply(x_batch[0,:,:],y_pred[0,:,:])\n",
    "        sp_y2_targ = np.multiply((np.ones(x_batch[0,:,:].shape)-y_batch[0,:,:]), x_batch[0,:,:])\n",
    "        sp_y2_rec = np.multiply((np.ones(x_batch[0,:,:].shape)-y_pred[0,:,:]), x_batch[0,:,:])\n",
    "\n",
    "        sp_y1_rec_phase = []\n",
    "        for i in range(len(sp_y1_rec)):\n",
    "            rec_line = []\n",
    "            for n in range(len(sp_y1_rec[0])) :\n",
    "                rec_line.append( sp_y1_rec[i][n]*np.cos(phase[i][n]) + 1j*sp_y1_rec[i][n]*np.sin(phase[i][n]) )\n",
    "\n",
    "            sp_y1_rec_phase.append(rec_line)\n",
    "            \n",
    "        sp_y2_rec_phase = []\n",
    "        for i in range(len(sp_y2_rec)):\n",
    "            rec_line = []\n",
    "            for n in range(len(sp_y2_rec[0])) :\n",
    "                rec_line.append( sp_y2_rec[i][n]*np.cos(phase[i][n]) + 1j*sp_y2_rec[i][n]*np.sin(phase[i][n]) )\n",
    "\n",
    "            sp_y2_rec_phase.append(rec_line)\n",
    "            \n",
    "        sp_y1_targ_phase = []\n",
    "        for i in range(len(sp_y1_targ)):\n",
    "            rec_line = []\n",
    "            for n in range(len(sp_y1_targ[0])) :\n",
    "                rec_line.append( sp_y1_targ[i][n]*np.cos(phase[i][n]) + 1j*sp_y1_targ[i][n]*np.sin(phase[i][n]) )\n",
    "\n",
    "            sp_y1_targ_phase.append(rec_line)\n",
    "            \n",
    "        sp_y2_targ_phase = []\n",
    "        for i in range(len(sp_y2_targ)):\n",
    "            rec_line = []\n",
    "            for n in range(len(sp_y2_targ[0])) :\n",
    "                rec_line.append(sp_y2_targ[i][n]*np.cos(phase[i][n]) + 1j*sp_y2_targ[i][n]*np.sin(phase[i][n]) )\n",
    "\n",
    "            sp_y2_targ_phase.append(rec_line)\n",
    "        \n",
    "        framerate=16000\n",
    "        t1, y1_targ = istft(sp_y1_targ_phase, fs=framerate)\n",
    "        print('Speaker A target')\n",
    "        IPython.display.display(IPython.display.Audio(y1_targ,rate=framerate))\n",
    "        \n",
    "        t1, y1_rec = istft(sp_y1_rec_phase, fs=framerate)\n",
    "        print('Speaker A prediction')\n",
    "        IPython.display.display(IPython.display.Audio(y1_rec,rate=framerate))\n",
    "        \n",
    "        t2, y2_targ = istft(sp_y2_targ_phase, fs=framerate)\n",
    "        print('Speaker B target')\n",
    "        IPython.display.display(IPython.display.Audio(y2_targ,rate=framerate))\n",
    "        \n",
    "        t2, y2_rec = istft(sp_y2_rec_phase, fs=framerate)\n",
    "        print('Speaker B prediction')\n",
    "        IPython.display.display(IPython.display.Audio(y2_rec,rate=framerate))\n",
    "\n",
    "        \n",
    "        plt.pcolormesh(10 * np.log10(x_batch[0,:,:]+1e-10))\n",
    "        plt.axis('tight')\n",
    "        plt.ylabel('Frequency [Hz]')\n",
    "        plt.xlabel('Time [sec]')\n",
    "        plt.title('Input')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        \n",
    "                       \n",
    "        plt.pcolormesh(y_batch[0,:,:])\n",
    "        plt.axis('tight')\n",
    "        plt.ylabel('Frequency [Hz]')\n",
    "        plt.xlabel('Time [sec]')\n",
    "        plt.title('Real mask')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.pcolormesh(y_pred[0,:,:])\n",
    "        plt.axis('tight')\n",
    "        plt.ylabel('Frequency [Hz]')\n",
    "        plt.xlabel('Time [sec]')\n",
    "        plt.title('Predicted mask')\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "        save_path = saver.save(sess, \"./model.ckpt\")\n",
    "    \n",
    "trainingLoop();\n",
    "\n",
    "\n",
    "    \n",
    "epoch = np.arange(len(train_loss))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_loss,'r', epoch, valid_loss,'b')\n",
    "plt.legend(['Train Loss','Val Loss'], loc=4)\n",
    "plt.xlabel('Epochs'), plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
